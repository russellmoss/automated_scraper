# Savvy Pirate v2.0

```
‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚£∞‚£ø‚£∑‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä
‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚£¥‚£ø‚£ø‚£ø‚†Ä‚†Ä‚¢Ä‚£†‚£§‚£∂‚£∂‚£∂‚£∂‚£∂‚£∂‚£∂‚£¶‚£§‚£Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚¢Ä‚£Ä‚£Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä
‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚£†‚£æ‚£ø‚£ø‚£ø‚£ø‚°î‚£æ‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚°ø‚¢ü‚£´‚£Ø‚£∑‚£æ‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£∑‚£Ñ‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä
‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚£†‚£æ‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£∑‚°ô‚¢ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚°ø‚¢ã‚£µ‚£æ‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ß‚°Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä
‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚¢Ä‚£Ä‚£§‚£∂‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£¶‚£ô‚†ø‚†ø‚†ø‚¢ü‚£´‚£æ‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚¢π‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£Ñ‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä
‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚¢Ä‚£§‚£æ‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚°á‚¢∏‚£ø‚£ø‚£ø‚°è‚†â‚†ô‚¢ø‚£ø‚£ø‚£¶‚°Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä
‚†Ä‚†Ä‚†Ä‚†Ä‚¢Ä‚£¥‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚†Ä‚£ø‚°ø‚°ç‚†≥‚£Ñ‚°Ä‚¢Ä‚£ø‚£ø‚£ø‚£ø‚£Ü‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä
‚†Ä‚†Ä‚†Ä‚¢Ä‚£º‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚°ø‚¢ø‚£ø‚¢ø‚°Ñ‚†∏‚°ø‚¢Ñ‚†õ‚£ò‚¢†‚£º‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ß‚°Ä‚†Ä‚†Ä‚†Ä‚†Ä
‚†Ä‚†Ä‚†Ä‚£æ‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£∑‚°û‚£º‚°ª‚°Ñ‚†≥‚°§‚†Ω‚†æ‚†ø‚†ø‚†ø‚¢õ‚£ª‚£ø‚£ø‚£ø‚£∑‚°Ä‚†Ä‚†Ä‚†Ä
‚†Ä‚†Ä‚†Ä‚¢ª‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£æ‚£ø‚£ø‚£Ñ‚†ô‚¢∂‚£∂‚£∂‚£∂‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ß‚†Ä‚†Ä‚†Ä
‚†Ä‚†Ä‚†Ä‚†Ä‚†ª‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚°ø‚†ü‚†õ‚†â‚¢â‚£Å‚£Ä‚£Ä‚£Ä‚£Ä‚£Ä‚£â‚°â‚†ô‚†õ‚†ª‚¢ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£Ø‚£ª‚£ç‚°≤‚¢ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚°Ñ‚†Ä‚†Ä
‚†Ä‚¢Ä‚°Ä‚£∂‚£§‚£å‚¢ª‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚†ø‚†ã‚£Å‚£§‚£∂‚£æ‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£∑‚£∂‚£§‚£à‚†õ‚¢ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£∑‚£æ‚£ø‚£ø‚£ø‚£ø‚£ø‚°ø‚†ü‚†õ‚†õ‚†Å‚†Ä‚†Ä
‚£∞‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ù‚¢ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ü‚£°‚£∂‚†ø‚¢õ‚£õ‚£â‚£≠‚£≠‚£§‚£§‚°¥‚†∂‚†∂‚†∂‚†∂‚¢≤‚£¥‚£§‚†≠‚†≠‚°≠‚£ü‚†ª‚†¶‚£ù‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚†ü‚¢â‚£Ä‚£†‚£∂‚£ø‚£Ü‚†Ä‚†Ä
‚†π‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ô‚†ª‚£ø‚£Æ‚£õ‚†ø‚£ø‚£ø‚£ø‚£´‚£µ‚°∂‚†ü‚£õ‚£ã‚£≠‚£≠‚£∂‚£∂‚£∂‚£∂‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£∂‚£æ‚£Æ‚£Ω‚£ø‚£ø‚£ø‚†ø‚†ü‚†õ‚†â‚¢Ä‚£¥‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£∂‚°Ä
‚†Ä‚†à‚†ô‚†ã‚†Å‚†Ä‚†à‚†â‚†õ‚†≥‚£≠‚£õ‚¢∑‚£¶‚£∏‚£ø‚£Ø‚£∂‚£æ‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚°è‚£ø‚†Ä‚†Ä‚†Ä‚£Ä‚£¥‚£æ‚£ø‚£ø‚£ø‚£ø‚°ü‚£ø‚£ø‚£ø‚£ø‚°á
‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚¢Ä‚£†‚£æ‚£ø‚£ø‚†ø‚†ø‚¢ø‚£π‚£ø‚£ß‚¢ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚¢∏‚°è‚£Ä‚£¥‚£æ‚£ø‚£ø‚†ø‚†õ‚†â‚†Ä‚†Ä‚†Ä‚†à‚†õ‚†õ‚†â‚†Ä
‚†Ä‚†Ä‚†Ä‚†Ä‚¢Ä‚£¥‚†ø‚†õ‚†ã‚†Å‚†Ä‚†Ä‚†Ä‚¢Ä‚£Ø‚¢ø‚£ø‚¢∏‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚°á‚£ø‚†£‚£ü‚°ª‚†ü‚†â‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä
‚†Ä‚†Ä‚†Ä‚†Ä‚†â‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚¢Ä‚£Ä‚£¥‚£æ‚£ø‚†à‚°ø‚£ø‚†É‚†Ä‚†Ä‚†Ä‚†à‚†â‚†õ‚†ª‚†ø‚£ø‚£ø‚£ø‚£ø‚£ø‚†ø‚†õ‚†â‚†â‚†Ä‚†à‚†â‚†õ‚£ø‚£Ω‚°ü‚†ã‚†Å‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä
‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚¢Ä‚£†‚£§‚£∂‚£æ‚£ø‚£ø‚£ø‚£ø‚£ø‚£Ä‚£º‚£ø‚†Å‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚£π‚°ü‚£ª‚£ø‚°É‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚¢π‚£∑‚£§‚°Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä
‚†Ä‚†Ä‚¢Ä‚£¥‚£æ‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚°ø‚¢π‚£ø‚£ø‚£ø‚°Ñ‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚£∞‚£ø‚¢£‚°á‚£ø‚£∑‚°Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚£º‚£ø‚£ø‚°á‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä
‚†Ä‚†Ä‚†ü‚†ã‚†ô‚†õ‚†ª‚£ø‚£ø‚£ø‚£ø‚£ø‚†è‚†Ä‚†à‚¢ø‚£ø‚£ø‚£ø‚£¶‚£Ñ‚£Ä‚£Ä‚£Ä‚£†‚£¥‚£ø‚£è‚°û‚¢ª‚£∏‚£ø‚£∑‚£Ñ‚†Ä‚†Ä‚£Ä‚£§‚†¥‚£æ‚£ø‚£ø‚£ø‚†É‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä
‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†π‚£ø‚£ø‚†É‚†Ä‚†Ä‚†Ä‚†à‚¢ø‚£ø‚£µ‚£æ‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚†Ä‚†Ä‚†Ä‚†π‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£∂‚†æ‚†ã‚†Å‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä
‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†ò‚£è‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚£Ä‚£º‚£ø‚°õ‚¢ø‚£ø‚£ø‚£ø‚£ø‚£ø‚°á‚†Ä‚†Ä‚†Ä‚†Ä‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚†ü‚£°‚£æ‚£Ü‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä
‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†ò‚†Ä‚†Ä‚¢†‚£∂‚£ø‚£ø‚£Ø‚£ø‚°á‚†Ä‚¢π‚£ø‚£ø‚£ø‚£ø‚£∑‚£§‚£§‚£¶‚£∂‚£ø‚£ø‚£ø‚£ø‚£ø‚°á‚†Ä‚£ø‚£ø‚¢∏‚£ø‚£∂‚£§‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä
‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚¢Ä‚£Ñ‚£†‚£¥‚£æ‚£ø‚£ü‚£ø‚†ü‚†Å‚£ø‚°á‚†Ä‚£ø‚°ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚°è‚°á‚¢Ä‚£ø‚£ø‚†ô‚¢Æ‚£õ‚†ø‚£∑‚£¶‚£Ñ‚£Ä‚£Ä‚£Ä‚£†‚£Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä
‚†Ä‚†Ä‚†Ä‚†Ä‚£¥‚£∂‚£∂‚£æ‚£ø‚£ø‚°ø‚£õ‚£Ω‚†û‚†ã‚†Ä‚†Ä‚†Ä‚£ø‚£∑‚†Ä‚£ç‚†á‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚†ø‚†â‚°Ñ‚£∏‚£ø‚°ø‚†Ä‚†Ä‚†à‚†ô‚†Æ‚£ü‚†ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚°Ü‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä
‚†Ä‚†Ä‚†Ä‚†Ä‚¢Ä‚£π‚£ø‚£ø‚£ø‚¢µ‚°ø‚†ã‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚¢ø‚£ø‚£¶‚£ø‚°∑‚£Ñ‚†ô‚†ø‚£ø‚¢π‚£ø‚£ø‚¢º‚°ø‚†ã‚£°‚£∂‚£≥‚£ø‚£ø‚£ø‚†É‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†à‚†ø‚†¨‚£ø‚£ø‚£ø‚£ø‚£ø‚£∑‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä
‚†Ä‚†Ä‚†Ä‚†Ä‚†∏‚£ø‚£ø‚£ø‚£ø‚†ü‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†ª‚£ø‚£ø‚£∑‚£ª‚¢ø‚£∂‚£¨‚£à‚£â‚£â‚£§‚£¥‚£ø‚£ª‚£æ‚£ø‚£ø‚†ü‚†Å‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚¢ø‚£ø‚£ø‚°ø‚†á‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä
‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†ô‚†ã‚†Å‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†à‚†ª‚£ø‚£ø‚£ø‚£ø‚°á‚£ø‚£á‚£ø‚¢π‚£ø‚£ø‚£ø‚£ø‚°ü‚†Å‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†à‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä
‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†ô‚¢ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚°ø‚†ã‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä
‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†ô‚¢ø‚£ø‚£ø‚£ø‚£ø‚°ø‚†è‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä
‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚°Ä‚°Å‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä
```

LinkedIn competitive intelligence Chrome extension - scrape and track competitor connections automatically.

## Features

- üîç **Automated LinkedIn Scraping** - Multi-layer extraction strategy resilient to LinkedIn DOM changes
- üìä **Google Sheets Integration** - Automatic data sync to Google Sheets with weekly tab management
- ‚è∞ **Scheduled Scraping** - Per-source scheduling with automated execution
- üîî **Zapier Webhooks** - Real-time notifications for scraping events with category filtering
- üìà **Tab Comparison** - Find new entries between different date tabs
- üîÑ **Retry Queue** - Local-first data queue with automatic retry on failures
- üéØ **Source Mapping** - Map multiple sources to different output workbooks
- üìú **Execution History** - Track all scraping runs with live profile count updates
- üîó **Clickable Links** - Direct links to scraped data in Google Sheets from execution history

## How It Works

### Architecture Overview

The extension uses a **three-layer architecture**:

1. **Content Script** (`content/content.js`)
   - Injected into LinkedIn search pages
   - Scrapes profile data using multi-layer selector strategy
   - Extracts: Name, Title, Location, LinkedIn URL, Accreditations
   - Sends scraped data to service worker via messages

2. **Service Worker** (`background/service_worker.js`)
   - Main orchestration hub (always running in background)
   - Manages OAuth authentication
   - Handles scheduling and queue processing
   - Coordinates manual and automated scraping
   - Sends notifications via webhooks

3. **Popup UI** (`popup/popup.js`)
   - User interface (persistent side panel)
   - Configuration and monitoring
   - Displays progress, schedules, execution history

### Data Flow

```
LinkedIn Page ‚Üí Content Script ‚Üí Service Worker ‚Üí Queue ‚Üí Google Sheets API ‚Üí Google Sheets
                                      ‚Üì
                                Webhook Notifications
```

### Scraping Process

1. **Navigation**: Extension navigates to LinkedIn search URL (or uses dedicated tab)
2. **Extraction**: Content script finds profile cards and extracts data using fallback selectors
3. **Validation**: Each profile is validated (name, valid LinkedIn URL)
4. **Queue**: Valid profiles are added to local queue
5. **Sync**: Queue processor syncs to Google Sheets (with retry on failure)
6. **Tracking**: Execution records track total profiles scraped

### Queue System

- **Local-First**: All scraped data is stored locally before syncing
- **Retry Logic**: Failed syncs retry with exponential backoff (up to 5 retries)
- **Failed Queue**: Items that exceed max retries are moved to failed queue
- **Automatic Processing**: Queue is processed every 30 seconds via alarm

### Scheduling System

- **Per-Source**: Each source (Connection) can have its own schedule
- **Weekly**: Schedules run once per week on specified day/time
- **Eastern Time**: All schedules use Eastern Time (America/New_York)
- **Automatic**: Service worker checks schedules every minute
- **Execution Records**: Each scheduled run creates an execution record

### Webhook Notifications

All notifications include:
- `type`: Specific notification type (schedule_started, scrape_failed, etc.)
- `category`: "status" or "error" (for easy Zapier filtering)
- `sourceName`: Connection Source name from Input Sheet
- `timestamp`: ISO timestamp
- `data`: Type-specific data (profiles scraped, error messages, etc.)

## Prerequisites

Before using this extension, you need:

1. **Google Cloud Project** with:
   - Google Sheets API enabled
   - Google Drive API enabled
   - OAuth 2.0 Client ID (Chrome Extension type)
   - Extension ID added to authorized redirect URIs

2. **Chrome Browser** (Manifest V3 compatible)

3. **Google Account** with access to Google Sheets

4. **Zapier Webhook URL** (optional, for notifications)

## Installation

### Step 1: Clone the Repository

```bash
git clone <repository-url>
cd automated_scraper
```

### Step 2: Create Your manifest.json

‚ö†Ô∏è **IMPORTANT**: `manifest.json` is in `.gitignore` for security because it contains your OAuth Client ID.

1. Copy the template file:
   ```bash
   cp manifest-template.json manifest.json
   ```

2. Edit `manifest.json` and replace `YOUR_CLIENT_ID.apps.googleusercontent.com` with your actual OAuth 2.0 Client ID from Google Cloud Console.

   Your `manifest.json` should look like this:
   ```json
   {
     "oauth2": {
       "client_id": "123456789-abc123xyz.apps.googleusercontent.com",
       ...
     }
   }
   ```

### Step 3: Get Your OAuth 2.0 Client ID

1. Go to [Google Cloud Console](https://console.cloud.google.com)
2. Select your project (or create a new one)
3. Navigate to **APIs & Services** > **Credentials**
4. Click **Create Credentials** > **OAuth client ID**
5. Choose **Chrome extension** as the application type
6. You'll need your Extension ID (see Step 4)
7. Copy the Client ID (it will look like: `123456789-abc123xyz.apps.googleusercontent.com`)
8. Add this Client ID to your `manifest.json`

### Step 4: Load the Extension in Chrome

1. Open Chrome and go to `chrome://extensions/`
2. Enable **Developer mode** (toggle in top right)
3. Click **Load unpacked**
4. Select the `automated_scraper` directory
5. Copy the **Extension ID** shown on the extensions page (you'll need this for OAuth setup)
6. Go back to Google Cloud Console and add this Extension ID to your OAuth credentials

### Step 5: Configure OAuth Consent Screen

1. In Google Cloud Console, go to **APIs & Services** > **OAuth consent screen**
2. Choose **Internal** or **External** (depending on your Google Workspace)
3. Fill in required fields:
   - App name: "Savvy Pirate"
   - User support email: Your email
   - Developer contact: Your email
4. Add scopes:
   - `https://www.googleapis.com/auth/spreadsheets`
   - `https://www.googleapis.com/auth/drive.file`
5. Save and continue

### Step 6: Test the Extension

1. Click the extension icon in Chrome toolbar
2. The side panel should open
3. You should be prompted to authenticate with Google (first time only)
4. After authentication, you can start configuring the extension

## Usage

### First-Time Setup

1. **Load Input Sheet**
   - Open the extension side panel (click extension icon)
   - Enter your Google Sheet URL or ID in "Input Sheet" section
   - Click "Load"
   - Your input sheet should have columns: Source Connection (column A), Target Job Title (column B), LinkedIn Search URL (column C)
   - The input sheet URL is automatically saved and persists across sessions

2. **Add Output Workbook**
   - Click "+ Add Workbook" in "Workbook Mappings" section
   - Enter Google Sheet URL or ID
   - Optionally map to a specific source
   - Click "Add Workbook"

3. **Map Sources to Workbooks**
   - In "Workbook Mappings", select a workbook for each source
   - Data from each source will be saved to its mapped workbook
   - Each source can have its own workbook

### Manual Scraping

Manual scraping automatically navigates through all searches for a selected source:

1. Open the extension side panel
2. Go to "üîç Manual Scraping" section
3. Select a source from the dropdown
4. Click "‚ñ∂ Start Scrape"
5. The extension will:
   - Navigate to the first search URL for that source
   - Scrape all profiles from all pages
   - Automatically move to the next search URL
   - Continue until all searches are complete
6. Monitor progress in real-time:
   - Progress bar shows completed/total searches
   - Execution history shows live profile count updates
7. Click "‚èπ Stop" to stop scraping at any time
8. All scraping occurs in a single dedicated tab (no new tabs opened)

**Note**: You must be logged into LinkedIn. The extension uses a dedicated browser tab for all scraping operations.

### Scheduled Scraping

1. Open the extension side panel
2. Go to "‚è∞ Schedules" section
3. Click "+ Add Schedule"
4. Select:
   - Source name (Connection Source from Input Sheet)
   - Day of week
   - Time (hour and minute) - uses Eastern Time
5. Click "Save Schedule"
6. The schedule will run automatically at the specified time
7. Toggle schedules on/off using the switch
8. View execution history in "üìú Execution History" section
9. Execution history shows:
   - Date and time
   - Source name (clickable link to scraped data)
   - Status (running/completed/failed)
   - Profiles scraped (updates live during scraping)
   - Click on source name or profile count to open the Google Sheets tab

### Compare Tabs

Compare two date tabs to find new entries:

1. Open the extension side panel
2. Go to "üìä Compare Tabs" section
3. Select a workbook
4. Select baseline tab (older data) and compare tab (newer data)
5. Enter output tab name (e.g., "New_12_16")
6. Select compare key:
   - **Name**: Compare by person's name
   - **LinkedIn URL**: Compare by LinkedIn profile URL (recommended, more accurate)
7. Click "Compare Tabs"
8. New tab will be created with only the differential entries (entries in compare tab but not in baseline tab)

### Settings

**Zapier Webhook**:
1. Go to "‚öôÔ∏è Settings" section
2. Enter your Zapier webhook URL
3. Click "Save Webhook URL"
4. Click "Test Webhook" to verify (sends a test `schedule_started` notification)

**Webhook Notification Categories**:

All notifications include a `category` field for easy filtering in Zapier:

- **"status"**: Regular notifications (schedule_started, schedule_completed)
- **"error"**: Error notifications (schedule_failed, scrape_failed, error)

**Recommended Zapier Setup**:

1. Use **Paths** in Zapier to branch notifications
2. Path 1: Filter `category` equals `"status"` ‚Üí Route to Status Channel
3. Path 2: Filter `category` equals `"error"` ‚Üí Route to Error Channel

**All webhook payloads include**:
- `type`: Notification type
- `category`: "status" or "error"
- `sourceName`: Connection Source name from Input Sheet (column A)
- `timestamp`: ISO timestamp
- `data`: Type-specific data

## Data Formats

### Input Sheet Format

The input sheet should have three columns:

| Column A | Column B | Column C |
|----------|----------|----------|
| Source Connection | Target Job Title | LinkedIn Search URL |

Example:
```
Taylor Matthews | Financial Advisor | https://www.linkedin.com/search/results/people/?origin=FACETED_SEARCH&connectionOf=...
Jeff Nash | Wealth Manager | https://www.linkedin.com/search/results/people/...
```

- **Column A (Source Connection)**: The name of the person whose connections you're scraping
- **Column B (Target Job Title)**: The job title to search for
- **Column C (LinkedIn Search URL)**: The full LinkedIn People search URL

**Multiple rows with the same Source Connection name** will all be scraped together when that source is selected.

### Output Sheet Format

Each workbook automatically creates weekly tabs named `MM_DD_YY` (Eastern Time):

| Date | Name | Title | Location | Connection Source | LinkedIn URL | Accreditation 1-6 |
|------|------|-------|----------|-------------------|--------------|-------------------|
| YYYY-MM-DD | John Doe, CFP¬Æ | Financial Advisor | New York, NY | Taylor Matthews | https://... | CFA |

**Columns**:
1. **Date**: Date scraped (YYYY-MM-DD)
2. **Name**: Person's name (accreditations extracted to separate columns)
3. **Title**: Job title
4. **Location**: Location
5. **Connection Source**: Source Connection from Input Sheet
6. **LinkedIn URL**: Full LinkedIn profile URL
7. **Accreditation 1-6**: Professional accreditations (CFA, CFP¬Æ, MBA, etc.)

**Tab Naming**: Output tabs are automatically named `MM_DD_YY` (Eastern Time), e.g., `12_17_24` for December 17, 2024.

## Troubleshooting

### Extension Won't Load

- Check that `manifest.json` is valid JSON
- Verify all required files exist (service worker, content script, popup)
- Check Chrome console for errors
- Ensure you created `manifest.json` from `manifest-template.json`

### OAuth Errors

- Verify Extension ID matches in Google Cloud Console
- Check redirect URI format: `https://<extension-id>.chromiumapp.org/`
- Re-authenticate by clicking extension icon
- Ensure OAuth Client ID in `manifest.json` matches Google Cloud Console
- Verify OAuth consent screen is configured correctly

### Service Worker Inactive

- Click extension icon to wake it
- Check service worker console: `chrome://extensions` ‚Üí "service worker" link
- Service worker should automatically wake when extension is used

### Scraping Finds 0 Profiles

LinkedIn frequently changes their DOM structure. To fix:

1. Navigate to a LinkedIn search page
2. Open browser console (F12)
3. Copy the content of `linkedin-diagnostic.js` and paste in console
4. Review output to identify new selectors
5. Update `SELECTORS` object in `content/content.js`
6. Reload extension

### Duplicate Rows or Invalid Data

If you see duplicate rows or rows with empty names:

1. The extension validates all profiles before adding to queue
2. Invalid profiles (empty names, invalid URLs) are skipped
3. Duplicates are prevented by URL-based deduplication
4. Use the "Deduplicate" feature in the popup footer if needed

### Data Not Appearing in Sheets

1. Check queue status in popup footer
2. Check for failed items (will show in footer)
3. Click "Retry Failed" to retry failed items
4. Check service worker console for errors
5. Verify workbook permissions (extension needs edit access)
6. Check Google Sheets API quota in Google Cloud Console

### Schedule Not Triggering

- Verify schedule is enabled (toggle switch in Schedules section)
- Check timezone (schedules use Eastern Time)
- Check service worker console for schedule logs
- Verify alarms are created: See debugging commands below
- Schedule checker runs every minute, so may take up to 1 minute after scheduled time

### Webhook Not Working

- Verify webhook URL is correct
- Check that Zapier webhook is active
- Test using "Test Webhook" button in Settings
- Check service worker console for webhook errors
- Verify `https://hooks.zapier.com/*` is in host_permissions (already included)

### Execution History Not Updating

- Execution history updates automatically when profiles are scraped
- If profile count isn't updating, check service worker console
- Reload the extension side panel to refresh the view
- Execution history is limited to last 100 records

## Debugging

### Service Worker Console

1. Go to `chrome://extensions`
2. Find "Savvy Pirate"
3. Click "service worker" link (opens DevTools)

### View Storage

In service worker console:
```javascript
chrome.storage.local.get(null, data => console.table(data));
```

### Check Alarms

In service worker console:
```javascript
chrome.alarms.getAll(alarms => {
    console.log('Active alarms:', alarms.map(a => ({
        name: a.name,
        next: new Date(a.scheduledTime).toLocaleString()
    })));
});
```

### Test Message Handlers

In service worker console:
```javascript
// Test ping
chrome.runtime.sendMessage({action: 'PING'}, console.log);

// Get queue status
chrome.runtime.sendMessage({action: 'GET_QUEUE_STATUS'}, console.log);

// Get schedules
chrome.runtime.sendMessage({action: 'GET_SCHEDULES'}, console.log);

// Get execution history
chrome.runtime.sendMessage({action: 'GET_EXECUTION_HISTORY', limit: 10}, console.log);
```

### Content Script Test

On a LinkedIn page, open browser console (F12):
```javascript
chrome.runtime.sendMessage({action: 'PING'}, r => console.log('Content script alive:', r));
```

## File Structure

```
automated_scraper/
‚îú‚îÄ‚îÄ manifest.json              # ‚ö†Ô∏è DO NOT COMMIT - contains your OAuth Client ID
‚îú‚îÄ‚îÄ manifest-template.json     # ‚úÖ Template for creating manifest.json
‚îú‚îÄ‚îÄ .gitignore                 # Excludes manifest.json and sensitive files
‚îú‚îÄ‚îÄ background/
‚îÇ   ‚îú‚îÄ‚îÄ service_worker.js      # Main orchestration hub
‚îÇ   ‚îú‚îÄ‚îÄ auth.js                # OAuth token management
‚îÇ   ‚îú‚îÄ‚îÄ sheets_api.js          # Google Sheets API wrapper
‚îÇ   ‚îú‚îÄ‚îÄ sync_queue.js          # Local queue with retry logic
‚îÇ   ‚îú‚îÄ‚îÄ scheduler.js           # Schedule management and execution history
‚îÇ   ‚îî‚îÄ‚îÄ notifications.js       # Zapier webhook notifications
‚îú‚îÄ‚îÄ content/
‚îÇ   ‚îî‚îÄ‚îÄ content.js             # LinkedIn DOM scraping
‚îú‚îÄ‚îÄ popup/
‚îÇ   ‚îú‚îÄ‚îÄ popup.html             # UI structure
‚îÇ   ‚îú‚îÄ‚îÄ popup.css              # Dark theme styling
‚îÇ   ‚îî‚îÄ‚îÄ popup.js               # UI controller
‚îú‚îÄ‚îÄ utils/
‚îÇ   ‚îî‚îÄ‚îÄ constants.js           # Shared constants
‚îú‚îÄ‚îÄ icons/
‚îÇ   ‚îú‚îÄ‚îÄ icon16.png
‚îÇ   ‚îú‚îÄ‚îÄ icon48.png
‚îÇ   ‚îî‚îÄ‚îÄ icon128.png
‚îú‚îÄ‚îÄ linkedin-diagnostic.js     # Selector maintenance tool
‚îî‚îÄ‚îÄ README.md                  # This file
```

## Log Prefixes

When debugging, look for these log prefixes in the service worker console:

- `[SW]` - Service worker (main orchestration)
- `[AUTH]` - Authentication
- `[QUEUE]` - Sync queue operations
- `[SHEETS]` - Sheets API calls
- `[SCHEDULE]` - Scheduling operations
- `[NOTIFY]` - Webhook notifications
- `[CS]` - Content script (in browser console on LinkedIn pages)
- `[POPUP]` - Popup UI

## Security Notes

‚ö†Ô∏è **IMPORTANT**:
- `manifest.json` contains your OAuth Client ID - keep it secure
- **Do NOT commit `manifest.json` to public repositories**
- `.gitignore` is configured to exclude sensitive files
- Use `manifest-template.json` as a template for others
- OAuth Client ID allows access to Google Sheets - treat it as a secret

## Key Features Explained

### Dedicated Scrape Tab

The extension uses a single dedicated browser tab for all scraping operations. This tab is:
- Created once and reused for all scraping sessions
- Saved in extension storage
- Automatically navigated to new search URLs
- Prevents opening multiple tabs during scraping

### Live Execution History

Execution history updates in real-time during scraping:
- Profile count updates as profiles are scraped
- Source name is clickable to open the Google Sheets tab
- Profile count is also clickable when > 0
- Links work even while scraping is running

### Weekly Tab Management

Output workbooks automatically create weekly tabs:
- Tab names: `MM_DD_YY` (Eastern Time)
- Tabs are created on first scrape of the week
- Headers are automatically added
- Old tabs are preserved (not deleted)

### Multi-Layer Selector Strategy

The content script uses a fallback selector strategy:
- Primary selectors (most reliable)
- Fallback selectors (backup if primary fails)
- Validation ensures data quality
- Prevents scraping invalid profiles

### Queue Retry System

Failed syncs are automatically retried:
- Exponential backoff (2s, 4s, 8s, 16s, 32s)
- Maximum 5 retries
- Failed items moved to failed queue after max retries
- Manual retry available from popup footer

## Support

For issues or questions:
1. Check troubleshooting section above
2. Review service worker console logs
3. Use `linkedin-diagnostic.js` if scraping fails
4. Check Google Sheets API quota if data sync fails
5. Review execution history for detailed error information

## License

[Add your license here]

---

**Version**: 2.0.0  
**Last Updated**: December 2024
